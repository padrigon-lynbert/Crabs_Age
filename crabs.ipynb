{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), 'CrabAgePrediction.csv'))\n",
    "df['Sex'] = df['Sex'].map({'F':0, 'I':2, 'M':3})\n",
    "df.head()\n",
    "\n",
    "X = df.drop('Age', axis=1)\n",
    "y = df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression Results:\n",
      "MSE: 5.02315541531175\n",
      "RMSE: 2.2399815138647434\n",
      "R^2: 0.514307535901118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # rmse: 2.2399\n",
    "from sklearn.pipeline import Pipeline   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "pipeline_linear = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('lin', LinearRegression())\n",
    "])\n",
    "\n",
    "classification_result_lr = cross_validate(pipeline_linear, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_lr = -classification_result_lr['test_neg_mean_squared_error']\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = classification_result_lr['test_r2']\n",
    "\n",
    "print(\"LinearRegression Results:\")\n",
    "print(\"MSE:\", mse_lr.mean())\n",
    "print(\"RMSE:\", rmse_lr.mean())\n",
    "print(\"R^2:\", r2_lr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Results:\n",
      "MSE: 4.8841122407278466\n",
      "RMSE: 2.2075865567504414\n",
      "R^2: 0.5274717069400165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor #  2.2075\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "classification_result_rf = cross_validate(pipeline_rf, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_rf = -classification_result_rf['test_neg_mean_squared_error']\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = classification_result_rf['test_r2']\n",
    "\n",
    "print(\"RandomForestRegressor Results:\")\n",
    "print(\"MSE:\", mse_rf.mean())\n",
    "print(\"RMSE:\", rmse_rf.mean())\n",
    "print(\"R^2:\", r2_rf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.308877096496005, 2.3017602992461748, 0.4868880715147833)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor #  2.3017\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('iskaler', StandardScaler()),\n",
    "    ('xgb', XGBRegressor(random_state='42'))\n",
    "])\n",
    "\n",
    "classification_result_xgb = cross_validate(pipeline_xgb, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse = - classification_result_xgb['test_neg_mean_squared_error']\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = classification_result_xgb['test_r2']\n",
    "\n",
    "mse.mean(), rmse.mean(), r2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.796621308172593, 2.188085955647151, 0.5362061207728999)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor #  2.1880\n",
    "\n",
    "pipeline_cat = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('catboost', CatBoostRegressor(random_state=42, silent=True))\n",
    "])\n",
    "\n",
    "classification_result_cat = cross_validate(pipeline_cat, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_cat = -classification_result_cat['test_neg_mean_squared_error']\n",
    "rmse_cat = np.sqrt(mse_cat)\n",
    "r2_cat = classification_result_cat['test_r2']\n",
    "\n",
    "mse_cat.mean(), rmse_cat.mean(), r2_cat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1296\n",
      "[LightGBM] [Info] Number of data points in the train set: 3114, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.986191\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1292\n",
      "[LightGBM] [Info] Number of data points in the train set: 3114, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.941875\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1302\n",
      "[LightGBM] [Info] Number of data points in the train set: 3114, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.935453\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1301\n",
      "[LightGBM] [Info] Number of data points in the train set: 3115, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.933226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1296\n",
      "[LightGBM] [Info] Number of data points in the train set: 3115, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.977207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.876315718725886, 2.2063601258901135, 0.5283077062913072)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor # 2.2063\n",
    "\n",
    "pipeline_lgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lgbm', LGBMRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "classification_result_lgb = cross_validate(pipeline_lgb, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_lgb = -classification_result_lgb['test_neg_mean_squared_error']\n",
    "rmse_lgb = np.sqrt(mse_lgb)\n",
    "r2_lgb = classification_result_lgb['test_r2']\n",
    "\n",
    "mse_lgb.mean(), rmse_lgb.mean(), r2_lgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Results:\n",
      "MSE: 4.770499137272676\n",
      "RMSE: 2.1830999552756216\n",
      "R^2: 0.5390335730695541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR # 2.1830\n",
    "\n",
    "pipeline_svr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "\n",
    "classification_result_svr = cross_validate(pipeline_svr, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_svr = -classification_result_svr['test_neg_mean_squared_error']\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "r2_svr = classification_result_svr['test_r2']\n",
    "\n",
    "print(\"SVR Results:\")\n",
    "print(\"MSE:\", mse_svr.mean())\n",
    "print(\"RMSE:\", rmse_svr.mean())\n",
    "print(\"R^2:\", r2_svr.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor Results:\n",
      "MSE: 5.245559800812458\n",
      "RMSE: 2.2891812288822253\n",
      "R^2: 0.49321511452136235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor # 2.2891\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "classification_result_knn = cross_validate(pipeline_knn, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_knn = -classification_result_knn['test_neg_mean_squared_error']\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "r2_knn = classification_result_knn['test_r2']\n",
    "\n",
    "print(\"KNeighborsRegressor Results:\")\n",
    "print(\"MSE:\", mse_knn.mean())\n",
    "print(\"RMSE:\", rmse_knn.mean())\n",
    "print(\"R^2:\", r2_knn.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Results:\n",
      "MSE: 4.638073032709989\n",
      "RMSE: 2.152211822843827\n",
      "R^2: 0.551703196172996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor # 2.1522\n",
    "\n",
    "catboost = CatBoostRegressor(random_state=42, silent=True)\n",
    "svr = SVR()\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "ensemble = VotingRegressor([\n",
    "    ('catboost', catboost),\n",
    "    ('svr', svr),\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "pipeline_ensemble = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ensemble', ensemble)\n",
    "])\n",
    "\n",
    "classification_result_ensemble = cross_validate(pipeline_ensemble, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_ensemble = -classification_result_ensemble['test_neg_mean_squared_error']\n",
    "rmse_ensemble = np.sqrt(mse_ensemble)\n",
    "r2_ensemble = classification_result_ensemble['test_r2']\n",
    "\n",
    "print(\"Ensemble Results:\")\n",
    "print(\"MSE:\", mse_ensemble.mean())\n",
    "print(\"RMSE:\", rmse_ensemble.mean())\n",
    "print(\"R^2:\", r2_ensemble.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1296\n",
      "[LightGBM] [Info] Number of data points in the train set: 3114, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.986191\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1292\n",
      "[LightGBM] [Info] Number of data points in the train set: 3114, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.941875\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1302\n",
      "[LightGBM] [Info] Number of data points in the train set: 3114, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.935453\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1301\n",
      "[LightGBM] [Info] Number of data points in the train set: 3115, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.933226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1296\n",
      "[LightGBM] [Info] Number of data points in the train set: 3115, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.977207\n",
      "Ensemble Results:\n",
      "MSE: 4.619479199830093\n",
      "RMSE: 2.1474953418935634\n",
      "R^2: 0.5534075340600946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the base models\n",
    "catboost = CatBoostRegressor(random_state=42, silent=True)\n",
    "svr = SVR()\n",
    "knn = KNeighborsRegressor()\n",
    "xgboost = XGBRegressor(random_state=42)\n",
    "lightgbm = LGBMRegressor(random_state=42)\n",
    "\n",
    "ensemble = VotingRegressor([\n",
    "    ('catboost', catboost),\n",
    "    ('svr', svr),\n",
    "    ('knn', knn),\n",
    "    ('xgboost', xgboost),\n",
    "    ('lightgbm', lightgbm)\n",
    "])\n",
    "\n",
    "pipeline_ensemble = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ensemble', ensemble)\n",
    "])\n",
    "\n",
    "classification_result_ensemble = cross_validate(pipeline_ensemble, X, y, cv=5, scoring=['neg_mean_squared_error', 'r2'])\n",
    "\n",
    "mse_ensemble = -classification_result_ensemble['test_neg_mean_squared_error']\n",
    "rmse_ensemble = np.sqrt(mse_ensemble)\n",
    "r2_ensemble = classification_result_ensemble['test_r2']\n",
    "\n",
    "print(\"Ensemble Results:\")\n",
    "print(\"MSE:\", mse_ensemble.mean())\n",
    "print(\"RMSE:\", rmse_ensemble.mean())\n",
    "print(\"R^2:\", r2_ensemble.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
